# # -*- coding: utf-8 -*-
# """DefenseofRomance.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1jL94xRGSbc3_50_qNQP-bsAYKT08h5lP

# In Defense of Happily Every After

# By: Sarah Bacharach


# ---

# **Sentiment Analysis**

# ---
# """

# import pandas as pd
# from textblob import TextBlob

# data = pd.read_csv('data.csv')

# data['description'] = data['description'].fillna('')

# data['description'] = data['description'].str.lower()

# sentiment_scores = []
# for description in data['description']:
#     blob = TextBlob(description)
#     sentiment_scores.append(blob.sentiment.polarity)

# data['Sentiment'] = sentiment_scores

# positive_descriptions = data[data['Sentiment'] > 0]
# negative_descriptions = data[data['Sentiment'] < 0]
# neutral_descriptions = data[data['Sentiment'] == 0]


# print("Positive Descriptions:")
# print(positive_descriptions[['title', 'description']])
# print("\nNegative Descriptions:")
# print(negative_descriptions[['title', 'description']])

# import pandas as pd
# from textblob import TextBlob
# import json

# data = pd.read_csv('data.csv')


# data['description'] = data['description'].fillna('')

# data['description'] = data['description'].str.lower()


# sentiment_scores = []
# for description in data['description']:
#     blob = TextBlob(description)
#     sentiment_scores.append(blob.sentiment.polarity)

# data['Sentiment'] = sentiment_scores


# positive_descriptions = data[data['Sentiment'] > 0]
# negative_descriptions = data[data['Sentiment'] < 0]
# neutral_descriptions = data[data['Sentiment'] == 0]


# sentiment_data = {
#     "positive": positive_descriptions[['title', 'description', 'Sentiment']].to_dict(orient='records'),
#     "negative": negative_descriptions[['title', 'description', 'Sentiment']].to_dict(orient='records'),
#     "neutral": neutral_descriptions[['title', 'description', 'Sentiment']].to_dict(orient='records')
# }


# with open('sentiment_data.json', 'w') as json_file:
#     json.dump(sentiment_data, json_file)

# print("Data exported to sentiment_data.json successfully.")

# """**Network Analysis**

# ---


# """

# import networkx as nx
# import matplotlib.pyplot as plt
# import json

# file_path = '/content/romance.json'
# with open(file_path, 'r') as file:
#     data = json.load(file)

# genres_list = [book["genres"] for book in data]

# G = nx.Graph()

# for genres in genres_list:
#     G.add_nodes_from(genres)

# for genres in genres_list:
#     for i in range(len(genres)):
#         for j in range(i+1, len(genres)):
#             G.add_edge(genres[i], genres[j])

# plt.figure(figsize=(12, 8))
# nx.draw(G, with_labels=True, node_color='lightblue', node_size=2000, font_size=10, font_weight='bold')
# plt.title('Genres Network Graph')
# plt.show()


# file_path = '/content/romance.json'
# with open(file_path, 'r') as file:
#     data = json.load(file)

# genres = set()
# for book in data:
#     genres.update(book['genres'])

# nodes = [{'id': genre} for genre in genres]
# links = []
# for book in data:
#     book_genres = book['genres']
#     for i in range(len(book_genres)):
#         for j in range(i+1, len(book_genres)):
#             links.append({'source': book_genres[i], 'target': book_genres[j]})

# processed_data = {'nodes': nodes, 'links': links}
# processed_file_path = '/content/processed_romance.json'
# with open(processed_file_path, 'w') as outfile:
#     json.dump(processed_data, outfile)

# print("Processing complete. JSON file saved successfully.")

# import json

# file_path = '/content/romance.json'
# with open(file_path, 'r') as file:
#     dataset = json.load(file)

# genre_counts = {}
# total_books = len(dataset)

# for book in dataset:
#     genres = book['genres']
#     for genre in genres:
#         if genre in genre_counts:
#             genre_counts[genre] += 1
#         else:
#             genre_counts[genre] = 1

# genre_percentages = {genre: (count / total_books) * 100 for genre, count in genre_counts.items()}

# for genre, percentage in genre_percentages.items():
#     print(f"{genre}: {percentage:.2f}%")

# """**GoodReads Scraper**

# ---


# """

# import requests
# from bs4 import BeautifulSoup


# def scrape_book_ids(url, headers):
#     book_ids = set()
#     try:
#         response = requests.get(url, headers=headers)
#         if response.status_code == 200:
#             soup = BeautifulSoup(response.content, 'html.parser')

#             book_links = soup.find_all('a', class_='bookTitle')
#             for link in book_links:
#                 book_id = link['href'].split('/')[-1].split('.')[0]
#                 title = link.text.strip()
#                 book_ids.add(f"{book_id}.{title}")
#         else:
#             print(f"Error: Failed to retrieve page {url} - Status Code: {response.status_code}")
#     except requests.exceptions.RequestException as e:
#         print(f"Error: An error occurred while scraping {url} - {e}")
#     return book_ids


# headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'}


# url_template = 'https://www.goodreads.com/shelf/show/romance?page={}'

# num_pages = 2

# total_book_ids = set()
# for page in range(1, num_pages + 1):
#     url = url_template.format(page)
#     page_book_ids = scrape_book_ids(url, headers)
#     total_book_ids.update(page_book_ids)

# with open('romance_book_ids3.txt', 'w') as f:
#     for book_id in total_book_ids:
#         f.write(f'{book_id}\n')

# print('Unique romance book IDs collected and saved to romance_book_ids.txt')

# """**Book Cover Analysis**

# ---


# """

# import csv
# import requests

# def fetch_romance_novels():
#     api_key = 'AIzaSyC-atPgBs2XkG62JoE24mqu63k43--BNfY'
#     url = 'https://www.googleapis.com/books/v1/volumes'

#     params = {
#         'q': 'subject:romance',
#         'filter': 'free-ebooks',
#         'maxResults': 40,
#         'key': api_key,
#         'printType': 'books',
#         'projection': 'full',
#         'minDate': '2000-01-01',
#         'maxDate': '2023-12-31'
#     }

#     novels = []
#     total_items = float('inf')
#     start_index = 0

#     while start_index < total_items:
#         params['startIndex'] = start_index
#         response = requests.get(url, params=params)

#         if response.status_code == 200:
#             data = response.json()
#             total_items = int(data.get('totalItems', 0))
#             items = data.get('items', [])

#             for item in items:
#                 volume_info = item.get('volumeInfo', {})
#                 title = volume_info.get('title', 'Unknown Title')
#                 authors = volume_info.get('authors', ['Unknown Author'])
#                 publisher = volume_info.get('publisher', 'Unknown Publisher')
#                 published_date = volume_info.get('publishedDate', 'Unknown Date')
#                 description = volume_info.get('description', 'No description available')
#                 isbn = volume_info.get('industryIdentifiers', [{}])[0].get('identifier', 'No ISBN')
#                 cover_url = volume_info.get('imageLinks', {}).get('thumbnail', 'No Cover URL')

#                 novel = {
#                     'title': title,
#                     'author': ', '.join(authors),
#                     'publisher': publisher,
#                     'published_date': published_date,
#                     'description': description,
#                     'isbn': isbn,
#                     'cover_url': cover_url
#                 }
#                 novels.append(novel)

#             start_index += len(items)
#         else:
#             print(f"Failed to fetch data. Status Code: {response.status_code}")
#             break

#     return novels

# def save_to_csv(data, filename):
#     keys = data[0].keys() if data else []
#     with open(filename, 'w', newline='', encoding='utf-8') as f:
#         writer = csv.DictWriter(f, fieldnames=keys)
#         writer.writeheader()
#         writer.writerows(data)

# romance_novels = fetch_romance_novels()
# save_to_csv(romance_novels, 'romance_novels.csv')
# print("Data saved to 'romance_novels.csv'.")

# import json

# with open('/content/drive/MyDrive/Major Studio 2/data.json') as f:
#     data = json.load(f)

# smutty_data = []
# diversity_data = []
# decorative_data = []
# photo_data = []

# for item in data:
#     if item.get("Man partially unclothed", "").upper() == "TRUE" or item.get("Woman partially unclothed", "").upper() == "TRUE":
#         smutty_data.append(item)
#     if item.get("Has POC", "").upper() == "TRUE":
#         diversity_data.append(item)
#     if item.get("Style", "") == "Illustrated":
#         decorative_data.append(item)
#     if item.get("Style", "") == "Photorealistic" and item.get("Man partially unclothed", "").upper() == "FALSE" and item.get("Woman partially unclothed", "").upper() == "FALSE" and item.get("Has POC", "").upper() == "FALSE":
#         photo_data.append(item)

# with open('smutty.json', 'w') as f:
#     json.dump(smutty_data, f, indent=4)

# with open('diversity.json', 'w') as f:
#     json.dump(diversity_data, f, indent=4)

# with open('decorative.json', 'w') as f:
#     json.dump(decorative_data, f, indent=4)

# with open('photo.json', 'w') as f:
#     json.dump(photo_data, f, indent=4)

# import json
# import csv

# def json_to_csv(input_file, output_file):
#     with open(input_file) as f:
#         data = json.load(f)

#     keys = data[0].keys()

#     with open(output_file, 'w', newline='') as f:
#         writer = csv.DictWriter(f, fieldnames=keys)
#         writer.writeheader()
#         for item in data:
#             writer.writerow(item)

# json_to_csv('smutty.json', 'smutty.csv')
# json_to_csv('diversity.json', 'diversity.csv')
# json_to_csv('decorative.json', 'decorative.csv')
# json_to_csv('photo.json', 'photo.csv')

# import csv

# def calculate_percentages(data_file):

#   year_data = {}
#   with open(data_file, 'r') as csvfile:
#     reader = csv.DictReader(csvfile)
#     for row in reader:
#       year = row.get("\ufeffyear")
#       if not year:
#         continue
#       if year not in year_data:
#         year_data[year] = {"decorative": 0, "smutty": 0, "diverse": 0, "total": 0}
#       year_data[year]["total"] += 1

#       # Category 1 (decorative)
#       if row.get("Style") == "Illustrated":
#         year_data[year]["decorative"] += 1

#       # Category 2 (smutty)
#       if row.get("Man partially unclothed", "FALSE").lower() == "true" or row.get("Woman partially unclothed", "FALSE").lower() == "true":
#         year_data[year]["smutty"] += 1

#       # Category 3 (diverse)
#       if row.get("Has POC", "FALSE").lower() == "true":
#         year_data[year]["diverse"] += 1

#   for year, stats in year_data.items():
#     for category, count in stats.items():
#       if category != "total" and stats["total"] > 0:
#         year_data[year][category] = (count / stats["total"]) * 100

#   return year_data

# def write_to_csv(data, filename):

#   years = list(data.keys())
#   categories = ["decorative", "smutty", "diverse"]
#   with open(filename, "w", newline="") as csvfile:
#     writer = csv.writer(csvfile)
#     writer.writerow(["Year"] + categories)
#     for year in years:
#       row = [year] + [data[year][category] for category in categories]
#       writer.writerow(row)


# data_file = "data.csv"

# percentages = calculate_percentages(data_file)


# write_to_csv(percentages, "category_percentages.csv")

# print("CSV file with category percentages created successfully!")

# import matplotlib.pyplot as plt

# # Data
# years = [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]
# smutty = [7.02, 2.52, 5.88, 6.67, 5.45, 9.26, 11.22, 17.5, 23.42, 45.76, 57.14, 61.34, 71.79]
# decorative = [29.82, 36.13, 27.73, 27.5, 27.27, 17.59, 17.35, 16.67, 9.01, 10.17, 5.88, 6.72, 2.56]
# diverse = [5.26, 6.72, 5.88, 4.17, 7.27, 5.56, 4.08, 5.0, 7.21, 20.34, 26.05, 38.66, 22.22]

# plt.figure(figsize=(10, 5))
# plt.plot(years, smutty, marker='o', label='Smutty')
# plt.title('Percentage of Smutty Books Over Time')
# plt.xlabel('Year')
# plt.ylabel('Percentage')
# plt.xticks(years, rotation=45)
# plt.grid(True)
# plt.legend()
# plt.tight_layout()
# plt.show()

# plt.figure(figsize=(10, 5))
# plt.plot(years, decorative, marker='o', color='orange', label='Decorative')
# plt.title('Percentage of Decorative Books Over Time')
# plt.xlabel('Year')
# plt.ylabel('Percentage')
# plt.xticks(years, rotation=45)
# plt.grid(True)
# plt.legend()
# plt.tight_layout()
# plt.show()

# plt.figure(figsize=(10, 5))
# plt.plot(years, diverse, marker='o', color='green', label='Diverse')
# plt.title('Percentage of Diverse Books Over Time')
# plt.xlabel('Year')
# plt.ylabel('Percentage')
# plt.xticks(years, rotation=45)
# plt.grid(True)
# plt.legend()
# plt.tight_layout()
# plt.show()